---
title: "Comparing Jungle to Drum & Bass music"
author: "Skip Vial"
date: "Februari 2021"
output: 
  flexdashboard::flex_dashboard:
    storyboard: true
    orientation: rows
---

```{r setup, include=FALSE}

library(tidyverse)
library(spotifyr)
library(usethis)
library(ggthemes)
library(compmus)
library(remotes)
library(plotly)
library(viridis)
library(hrbrthemes)
library(plyr)
```



### *Track Breakdown* - Self-Similarity Matrices of a **Ragga Drum & Bass track**

```{r out.width= "50%"} 

test <-
  get_tidy_audio_analysis("5jeAriText11q771wlloPR") %>% # Change URI.
  compmus_align(bars, segments) %>%                     # Change `bars`
  select(bars) %>%                                      #   in all three
  unnest(bars) %>%                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  ) %>%
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  )

# SELF SIMILARITY MATRIX
compmus_long_distance(
  test %>% mutate(pitches = map(pitches, compmus_normalise, "chebyshev")),
  test %>% mutate(pitches = map(pitches, compmus_normalise, "chebyshev")),
  feature = pitches,
  method = "euclidean"
) %>%
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_equal() +
  labs(x = "Time (s)", 
       y = "Time (s)",
       title = "Chroma Features") +
  theme_minimal() +
  scale_fill_viridis_c(guide = NULL)

# CEPTOGRAM
test %>%
  compmus_self_similarity(timbre, "cosine") %>% 
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "Time (s)", 
       y = "Time (s)",
       title = "Timbre Features")

```

***

A track from the Ragga Drum & Bass genre is chosen for the comparison of pitch-based and timbre-based features because tracks from this genre have not been discussed yet.

*Track: [No Diggity - Kursiva, Mooncat, Earth Beat Movement](https://open.spotify.com/track/5jeAriText11q771wlloPR?si=bsTOoXsKT9m4Pp1EOJVTHg)*

Interestingly, there are only small differences between the two self-similarity matrices. This track's **overall structure is very similar** to the structure of tracks that we have discussed. The intro is visible in the lower left corner. Usually, there are diagonal lines in the chroma-based matrix when there is repetition in a track, for example when a chorus is played multiple times. This is not the case for Drum & Bass tracks. **The repetition takes on a different form**, and therefore there are almost no diagonal lines present in the matrix. 

Small changes in texture can be seen in the timbre-based matrix, especially **at approximately 190 seconds**. This section of the track is after a breakdown and is therefore very quiet. Suddenly, a **short and loud electronic melody** is played, which causes the change of color in the timbre-based matrix. This is **not a change in pitch** and therefore the differences are not visible in the pitch-based matrix.



### Welcome to my portfolio!

*Background*

The music genre ‘Jungle’ emerged in the 1990s and is viewed as the direct originating point for the newer music genre named ‘Drum & Bass’ (emerged mid 1990s). These two genres are commonly used as synonyms for one another. Almost 30 years have passed since these genres were developed. During this time the Drum & Bass genre has grown significantly in terms of exposure and now knows many subgenres, while Jungle music did not make the same growth and lost popularity. What caused this turn of events? Has Drum & Bass become more popular because of its diversity? Can we still use the terms ‘Jungle’ and ‘Drum & Bass’ as synonyms or has Drum & Bass developed in such a way that it has become completely different from its originating point? This corpus analysis attempts to answer these questions by comparing Jungle music to various subgenres of Drum & Bass music:

- Ragga Drum & Bass. This subgenre was inspired by the original Ragga Jungle style, which was very popular at the time. Expected is that this genre is most similar to the original Jungle music.

- Light Drum & Bass. Also called Liquid Drum & Bass. Many harmonic and melodic grooves are used, as well as samples from funk, jazz, soul, R&B. Expected is that this subgenre has significant differences from Jungle. Overall, Liquid Drum & Bass is known for its positive energy. This would mean that the acousticness and/or valence of songs are different than in Jungle music.

- Heavy Drum & Bass. This subgenre has a general ‘dark’ mood, which is realized with deeper basslines and more industrial, hardcore (electronic) melodies.

*** 

*Corpus*

This corpus uses genre-based Spotify Playlists.

- Jungle:
  - JUNGLE / RAGGA DNB / JUNGLE REVIVAL
  - Tracks: 125
  
- Ragga DnB: 
  - Ragga Drum and Bass
  - Tracks: 115
  
- Light DnB:
  - Liquid Drum and Bass 	
  - Tracks: 100
  
- Heavy DnB:
  - Neurofunk Drum & Bass
  - NEUROFUNK 2021 // Updated Weekly
  - Tracks: 113
  

```{r echo=FALSE}

### Import Spotify Playlists ###
Jungle <- get_playlist_audio_features("", "4Xq7CHKa693iezbOXH8NOQ")

RaggaDnB <- get_playlist_audio_features("", "0ix8qCnYCiu4w8OcnK0Uqu")

LightDnB <- get_playlist_audio_features("", "5ABMzUESx7K7EyowE5kFCl")

Heavy1 <- get_playlist_audio_features("", "7Dx1mjAUeV8ElB5FERajkl")
Heavy2 <- get_playlist_audio_features("", "0Po1Xhn50bsrQwyjXWMMKJ")


### Combine datasets per subgenre ###
HeavyDnB <-
  bind_rows(
    Heavy1 %>% mutate(category = "Heavy1"),
    Heavy2 %>% mutate(category = "Heavy2")
  )


### Final final universal dataframe ###
all_music <-
  bind_rows(
      Jungle %>% mutate(category = "Jungle"),
      RaggaDnB %>% mutate(category = "RaggaDnB"),
      LightDnB %>% mutate(category = "LightDnB"),
      HeavyDnB %>% mutate(category = "HeavyDnB")
  )

### Delete useless columns ###
all_music = subset(all_music, select = -c(playlist_id, playlist_img, playlist_owner_name,
                                    playlist_owner_id, track.id, analysis_url,
                                    is_local, primary_color, added_by.href,
                                    added_by.id, added_by.type, added_by.uri,
                                    added_by.external_urls.spotify, track.artists,
                                    track.available_markets, track.disc_number,
                                    track.episode, track.explicit, track.href,
                                    track.is_local, track.preview_url, track.track,
                                    track.track_number, track.type, track.uri,
                                    track.album.album_type, track.album.artists,
                                    track.album.available_markets, track.album.href,
                                    track.album.id, track.album.images, 
                                    track.album.name, added_at,
                                    track.album.release_date_precision,
                                    track.album.total_tracks, track.album.type,
                                    track.album.uri, track.album.external_urls.spotify,
                                    track.external_ids.isrc, 
                                    track.external_urls.spotify, video_thumbnail.url
                                    ))


```



###  First, we investigate **how much vocals** are used in each genre

```{r }

# Violin plot instrumentalness per genre
instrumentalness <- all_music %>%
  ggplot( aes(x=instrumentalness, 
              y=category, 
              fill=category, 
              color=category,)) +
    geom_violin(width=1.6, size=0.5) +
    labs(x = "Instrumentalness",
         title = "",
         subtitle = "The distribution of instrumentalness per genre",
         caption = ""
         ) + 
    scale_fill_viridis(discrete=TRUE) +
    scale_color_viridis(discrete=TRUE) +
    theme_ipsum() +
    theme(
      legend.position="none",
      axis.title.y = element_blank(),
      plot.subtitle = element_text(face = "bold",
                                   size = 14),
      axis.title.x = element_text(size = 10)
    ) 

instrumentalness
```

***



Instrumentalness predicts whether a track contains vocals or not. A value of 0.5 or higher represents a track that contains no vocal content. In this plot, **the thickness of the line represents the amount of tracks** that have the same instrumentalness value. This plot shows a pattern between the genres that was expected. The genres **Jungle and RaggaDnB** are very similar and both contain **mostly vocal tracks** since most tracks have an instrumentalness value between 0 and 0.25.  

LightDnB and HeavyDnB also show a somewhat similar distribution. The differences between these genres is that **HeavyDnB contains mostly non-vocal tracks**, where **LightDnB** shows an almost **equal amount of vocal and non-vocal tracks**.



### Second, Is it possible that the **presence of vocals influences other features**? 

```{r out.width="110%"}

# Scatterplot energy, valence and danceability
energy_valence <- ggplot(all_music, 
       aes(energy, 
           valence, 
           color = danceability)) + 
  geom_point(position = "jitter", alpha = 0.7, shape = 20) +
      scale_fill_viridis(discrete=FALSE) +
    scale_color_viridis(discrete=FALSE) +
  theme_light() +
  facet_wrap(~ category) +
    labs(     
    x = "Energy",
    y = "Valence",
    color = "Danceability",
    title = "Energy, valence and danceability per genre",
    caption = "") +
      theme(plot.title = element_text(face = "bold",
                                   size = 14),
      axis.title.x = element_text(size = 10),
      axis.title.y = element_text(size = 10)
    ) 

energy_valence


```

***

***Energy***

The energy value ranges from 0.0 to 1.0. A higher value means that the track feels fast, loud and noisy.

It becomes clear that the genre HeavyDnB consists mostly of tracks with very high energy. This was expected since this genre draws influence from hardcore music, for example. The genres Jungle and RaggaDnB also show many tracks with high energy, possibly because there always is a consistent drum pattern in addition to vocals. LightDnB tracks show more variety in the amount of energy. This is not surprising as this genre is usually has a 'laid-back' feel to it.

***Valence***

Valence describes how positive a track feels. A high valence corresponds to a more happy or euphoric track. Tracks with low valence sound more sad, depressed or angry.

As for valence, the genres can be divided into two groups. HeavyDnB and LightDnB show a tendency for tracks with low valence, whereas Jungle and RaggaDnB consist of tracks with a general high valence. In the first plot we could see the same split between these genres. Is it possible that the presence of vocals influences this other features?

*Note: it is surprising that LightDnB has many tracks with low valence. A general high valence was expected here, since this genre is considered as the more 'feel-good' subgenre of Drum & Bass*.

***Danceability***

Danceability describes how suitable a track is for dancing. A value of 0.0 means that the track is least danceable and a value of 1.0 is most danceable. In this plot, a light color represents a high danceability and a dark color represents low danceability.

The genres can be divided in the same manner as with valence. Jungle and RaggaDnB have more tracks than HeavyDnB and LightDnB that are considered 'danceable' by Spotify. 

Now why is that? The biggest difference measured between the genres is that Jungle and RaggaDnB often have vocals in tracks, whereas HeavyDnB and Light DnB have more non-vocal tracks. It is possible that there is a relationship between the presence of vocals and the features described here. Possibly, **the presence of vocals positively influences valence and/or danceability**. 


### And the **most popular** genre is...

```{r}

# Plot track popularity

popularity_means <- ddply(all_music, "category", summarise, grp.mean=mean(track.popularity))


plot_popularity <- all_music %>% ggplot(aes(x = track.popularity,
                         fill = category
                         )) +
  geom_histogram(binwidth = 1,
                 alpha = 0.7) +
  geom_vline(data = popularity_means, aes(xintercept = grp.mean, 
                                          color = category),
                                          size = 1,
                                          alpha = 0.8,
                                          linetype = "dashed") +
  labs(title = "The popularity of tracks per genre",
       x = "Popularity",
       y = "Count") +
    scale_fill_viridis(discrete=TRUE) +
    scale_color_viridis(discrete=TRUE) +
  theme_ipsum() +
  theme(legend.title = element_blank()
        )

  ggplotly(plot_popularity)
  


```

***

In construction



### *Chromagram Comparison 1* - What does the general build up of a Light Drum & Bass track look like?

```{r}

# Get track information
fall_to_you <-
  get_tidy_audio_analysis("1ObLc50qTIp8gF1Lg2GimH") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)

# Make the chromagram. Use manhattan, euclidean, chebyshev
chroma_fall_to_you <- fall_to_you %>%
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) %>%
  compmus_gather_chroma() %>% 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c()

# Add lines and text at key moments
chroma_fall_to_you +
  geom_vline(xintercept = 89,
             color = "white",
             size = 0.8) +
  geom_vline(xintercept = 200,
             color = "white",
             size = 0.8) + 
  geom_vline(xintercept = 223,
             color = "white",
             size = 0.8) +
  geom_vline(xintercept = 356,
             color = "white",
             size = 0.8) +
  annotate(geom="text", 
          x=89, 
          y="A", 
          label="First drop",
          color="white",
          fontface = 2,
          hjust=0) +
  annotate(geom="text", 
          x=200, 
          y="B", 
          label="Breakdown",
          color="white",
          fontface=2,
          hjust=1) +
  annotate(geom="text", 
          x=223, 
          y="A", 
          label="Second drop",
          color="white",
          fontface=2,
          hjust=0) +
  annotate(geom="text", 
          x=356, 
          y="B", 
          label="Breakdown",
          color="white",
          fontface=2,
          hjust=1)


```

***

*Track: [Falls to you VIP - Calibre](https://open.spotify.com/track/1ObLc50qTIp8gF1Lg2GimH?si=5kqgrc7bQU249rXaCZ9BmQ)*

This track was chosen because it shows some aspects that usually are present in Light Drum & Bass tracks. The intro of the song lasts from the beginning until the first drop. What stands out here is that **the intro is relatively long**, it lasts approximately 90 seconds. Light Drum & Bass tracks usually have a longer intro than other genres because **the average build up is very slow**. 

The middle part of the song starts after the first drop. This is usually the part where a consistent 'Drum & Bass' drum pattern is played until the breakdown. A number of **samples are then layered** on top of each other. This creates the unique sound of the song. The samples used in this genre contains a lot of **harmonic and melodic grooves**, which makes this genre very pleasant to listen to.
This pattern of a drop followed by a breakdown is then repeated one more time. There could be small variations of the samples used, but in general, this second part sounds the same as the first.

After the second breakdown, **one final chord** is played to indicate that the song has come to an end. This is the typical way a Light Drum & Bass track ends.



### *Chromagram Comparison 2* - And for Heavy Drum & Bass?

```{r}

# Get track information
faceless <-
  get_tidy_audio_analysis("2m40HRbLhNf3FeH9ntqQWw") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)



# Make the chromagram. Use manhattan, euclidean, chebyshev
chroma_faceless <- faceless %>%
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) %>%
  compmus_gather_chroma() %>% 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL , fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c()

# Add lines and text at key moments
chroma_faceless +
  geom_vline(xintercept = 40,
             color = "white",
             size = 0.8) +
  geom_vline(xintercept = 110,
             color = "white",
             size = 0.8) + 
  geom_vline(xintercept = 133,
             color = "white",
             size = 0.8) +
  geom_vline(xintercept = 207,
             color = "white",
             size = 0.8) +
  annotate(geom="text", 
          x=40, 
          y="A", 
          label="First drop",
          color="white",
          fontface = 2,
          hjust=0) +
  annotate(geom="text", 
          x=110, 
          y="B", 
          label="Breakdown",
          color="white",
          fontface=2,
          hjust=1) +
  annotate(geom="text", 
          x=133, 
          y="A", 
          label="Second drop",
          color="white",
          fontface=2,
          hjust=0) +
  annotate(geom="text", 
          x=207, 
          y="B", 
          label="Breakdown",
          color="white",
          fontface=2,
          hjust=1)


```

***

*Track: [Faceless - Phace, Was A Be](https://open.spotify.com/track/2m40HRbLhNf3FeH9ntqQWw?si=5NqhOLJpSZiJIYiQmn1Atw)*

The intro of this song shows how a typical Heavy Drum & Bass track starts. **The drops are usually more intense**. This means that the build up to the drop starts early in the song. You can see this in the first part of the chromagram. The notes that are played (yellow) seem to have a staircase-like form. Playing a higher note each time will make the listener anticipate more and more to the drop. 

The middle part of tracks are unique in the sense that the underlying 'Drum & Bass' **drum pattern becomes harder to recognize**. Lots of deep basslines and samples with heavy electronic melodies are used in this part. Also, vocals are not used. This is why the chromagram looks so consistent.
Nothing interesting happens after the first breakdown. Just a few tones are played, and after a while a similar build up as before the first drop is used to anticipate towards the second drop.

The **ending of the track starts after the second breakdown**. Sometimes a Heavy Drum & Bass track ends instantly after the second breakdown. But in this case, a final sample (which still sounds pretty restless) is introduced prior to the breakdown. At some point the main samples stop, and the final sample is played for a short time before ending.



### *Chromagram Comparison 3* - Now, what is different in the build up of a typical Jungle song?

```{r}

# Get track information
good_enough <-
  get_tidy_audio_analysis("6tTn8EkWFZJHkuDXLI3Hzg") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)

# Make the chromagram. Use manhattan, euclidean, chebyshev
chroma_good_enough <- good_enough %>%
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) %>%
  compmus_gather_chroma() %>% 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c()

# Add lines and text at key moments
chroma_good_enough +
  geom_vline(xintercept = 45,
             color = "white",
             size = 0.8) +
  geom_vline(xintercept = 154,
             color = "white",
             size = 0.8) + 
  geom_vline(xintercept = 176,
             color = "white",
             size = 0.8) +
  geom_vline(xintercept = 265,
             color = "white",
             size = 0.8) +
  annotate(geom="text", 
          x=45, 
          y="A", 
          label="First drop",
          color="white",
          fontface = 2,
          hjust=0) +
  annotate(geom="text", 
          x=154, 
          y="B", 
          label="Breakdown",
          color="white",
          fontface=2,
          hjust=1) +
  annotate(geom="text", 
          x=176, 
          y="A", 
          label="Second drop",
          color="white",
          fontface=2,
          hjust=0) +
  annotate(geom="text", 
          x=265, 
          y="B", 
          label="Breakdown",
          color="white",
          fontface=2,
          hjust=1)

```

***

*Track: [Good Enough - Serial Killaz](https://open.spotify.com/track/6tTn8EkWFZJHkuDXLI3Hzg?si=eVMR2tO7Ta-UVtvT4_1_xQ)*

This track would be the average 'Jungle' track. A 'Drum & Bass' **drum pattern starts a few seconds after the track begins**. This is played until the first drop.

In this genre, **drops are usually introduced by vocals**. The vocal part begins, and a bassline is added so that the track sounds more 'complete'. The chromagram's pattern of the middle parts of this track seem different when compared to the other tracks discussed, because **vocals are included here**. The vocals and the samples have their own sound, this is why multiple notes show a high magnitude (yellow). 

It is common for Jungle tracks to **end the song by using the same samples as in the intro** of the track.



### Conclusion / Discussion (In construction)

In construction

***

Panel is in construction
